ylim = ylim_range)
abline(v = n, lty = 2, col = "gray30", lwd = 1.5)
text(n, ylim_range[2], "Forecast start", pos = 2, col = "gray30")
forecast_times <- (n+1):(n+h)
for(a in alphas) {
forecast_data <- forecasts[[as.character(a)]]
# Add 90% prediction interval (semi-transparent)
polygon(c(forecast_times, rev(forecast_times)),
c(forecast_data$lower, rev(forecast_data$upper)),
col = adjustcolor(colors[[as.character(a)]], alpha.f = 0.2),
border = NA)
# Add median forecast
lines(forecast_times, forecast_data$median,
col = colors[[as.character(a)]], lwd = 2.5)
}
legend("topleft",
legend = c("Observed", paste("α =", alphas)),
col = c("black", sapply(as.character(alphas), function(x) colors[[x]])),
lwd = 2,
cex = 0.8,
bg = "white")
# Print forecast statistics with prediction intervals
cat("\n=== Forecast Statistics with Prediction Intervals ===\n")
for(a in alphas) {
forecast_data <- forecasts[[as.character(a)]]
cat(sprintf("\nα = %.1f:\n", a))
cat(sprintf("  Median forecast at h=1: %.2f [%.2f, %.2f]\n",
forecast_data$median[1], forecast_data$lower[1], forecast_data$upper[1]))
cat(sprintf("  Median forecast at h=20: %.2f [%.2f, %.2f]\n",
forecast_data$median[h], forecast_data$lower[h], forecast_data$upper[h]))
cat(sprintf("  PI width at h=1: %.2f\n",
forecast_data$upper[1] - forecast_data$lower[1]))
cat(sprintf("  PI width at h=20: %.2f\n",
forecast_data$upper[h] - forecast_data$lower[h]))
cat(sprintf("  PI growth rate: %.2f%%\n",
100 * ((forecast_data$upper[h] - forecast_data$lower[h]) /
(forecast_data$upper[1] - forecast_data$lower[1]) - 1)))
}
# Optional: Plot some individual simulated paths for one alpha to show variability
par(mfrow = c(1, 1), mar = c(4, 4, 3, 1))
a_example <- 0.3
forecast_data <- forecasts[[as.character(a_example)]]
xlim_range <- c(max(1, n-20), n + h)
ylim_range <- range(c(Y[(n-20):n], forecast_data$all_paths))
plot(1:n, Y, type = "l", col = "black", lwd = 2,
xlab = "Time", ylab = "Value",
main = bquote("Simulated Forecast Paths for α = " ~ .(a_example)),
xlim = xlim_range,
ylim = ylim_range)
abline(v = n, lty = 2, col = "gray30", lwd = 1.5)
forecast_times <- (n+1):(n+h)
# Plot a sample of simulated paths
n_paths_to_plot <- 50
sample_paths <- sample(1:nrow(forecast_data$all_paths), n_paths_to_plot)
for(path_idx in sample_paths) {
lines(forecast_times, forecast_data$all_paths[path_idx, ],
col = adjustcolor(colors[[as.character(a_example)]], alpha.f = 0.1),
lwd = 0.5)
}
# Add median forecast on top
lines(forecast_times, forecast_data$median,
col = colors[[as.character(a_example)]], lwd = 3)
# Add prediction intervals
lines(forecast_times, forecast_data$lower,
col = colors[[as.character(a_example)]], lwd = 2, lty = 2)
lines(forecast_times, forecast_data$upper,
col = colors[[as.character(a_example)]], lwd = 2, lty = 2)
legend("topleft",
legend = c("Observed", "Simulated paths", "Median forecast", "90% PI"),
col = c("black",
adjustcolor(colors[[as.character(a_example)]], alpha.f = 0.3),
colors[[as.character(a_example)]],
colors[[as.character(a_example)]]),
lwd = c(2, 1, 3, 2),
lty = c(1, 1, 1, 2),
cex = 0.8,
bg = "white")
# Plotting
par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))
# Define colors
colors <- list("0" = "gray50", "0.1" = "blue", "0.3" = "green",
"0.7" = "orange", "1" = "red")
# Plot for each alpha
plot_alphas <- c(0, 0.1, 0.3, 1.0)
for(a in plot_alphas) {
# Extend x-axis to include forecast horizon
xlim_range <- c(1, n + h)
# Calculate y-axis limits including forecasts
forecast_data <- forecasts[[as.character(a)]]
ylim_range <- range(c(Y, results[, grep("level", names(results))],
forecast_data$lower, forecast_data$upper))
# Plot observed series
plot(1:n, Y, type = "l", pch = 20, col = "black", cex = 0.8,
xlab = "Time", ylab = "Value",
main = bquote("α = " ~ .(a) ~ " with 90% Prediction Interval"),
xlim = xlim_range,
ylim = ylim_range)
# Mark the large error
abline(v = 50, lty = 2, col = "darkred", lwd = 1.5)
abline(v = n, lty = 2, col = "gray30", lwd = 1)
text(n, ylim_range[1], "Forecast", pos = 4, col = "gray30", cex=0.8)
# Add level line
level_col <- paste0("level_alpha_", a)
lines(1:n, results[[level_col]], col = colors[[as.character(a)]], lwd = 2)
# Add forecast
forecast_times <- (n+1):(n+h)
# Add 90% prediction interval (outer, lighter shade)
polygon(c(forecast_times, rev(forecast_times)),
c(forecast_data$lower, rev(forecast_data$upper)),
col = adjustcolor(colors[[as.character(a)]], alpha.f = 0.15),
border = NA)
# Add 50% prediction interval (inner, darker shade)
polygon(c(forecast_times, rev(forecast_times)),
c(forecast_data$lower_50, rev(forecast_data$upper_50)),
col = adjustcolor(colors[[as.character(a)]], alpha.f = 0.3),
border = NA)
# Add median forecast
lines(forecast_times, forecast_data$median,
col = colors[[as.character(a)]], lwd = 2.5, lty = 1)
# Connect last level to first forecast
lines(c(n, n+1), c(results[[level_col]][n], forecast_data$median[1]),
col = colors[[as.character(a)]], lwd = 2.5, lty = 1)
# Add legend
legend("topright",
legend = c("Observed", "Fitted level", "Forecast median", "50% PI", "90% PI"),
col = c("black", colors[[as.character(a)]], colors[[as.character(a)]],
colors[[as.character(a)]], colors[[as.character(a)]]),
lwd = c(1, 2, 2.5, NA, NA),
lty = c(1, 1, 1, NA, NA),
pch = c(NA, NA, NA, 15, 15),
pt.cex = c(NA, NA, NA, 2, 2),
fill = c(NA, NA, NA,
adjustcolor(colors[[as.character(a)]], alpha.f = 0.3),
adjustcolor(colors[[as.character(a)]], alpha.f = 0.15)),
border = c(NA, NA, NA, NA, NA),
cex = 0.65,
bg = "white")
}
# Exponential Smoothing Illustration with Series and Prediction Intervals
set.seed(123)
# Parameters
n <- 100
true_level0 <- 100
alphatrue <- 0.4
sd_error <- 10
h <- 20  # forecast horizon
# Generate data with a level shift
errors <- rnorm(n, 0, sd_error)
errors[50] <- 30  # Introduce a large error at t=50
true_level <- c()
# Generate observed series: Y_t = level_{t-1} + error_t
Y <- numeric(n)
Y[1] <- true_level0 + errors[1]
for(t in 2:n) {
if (t==2){
true_level[t-1] = true_level0 + alphatrue*errors[t-1]
} else {
true_level[t-1] = true_level[t-2] + alphatrue*errors[t-1]
}
Y[t] <- true_level[t-1] + errors[t]
}
# Function to apply exponential smoothing
exp_smooth <- function(Y, alpha, initial_level) {
n <- length(Y)
level <- numeric(n + 1)
level[1] <- initial_level
for(t in 1:n) {
error_t <- Y[t] - level[t]
level[t + 1] <- level[t] + alpha * error_t
}
return(level[-1])  # Remove initial level
}
# Function to simulate h-step ahead forecasts and return prediction intervals
simulate_forecast <- function(last_level, alpha, h, sd_error, n_sim=1000, prob=0.90) {
# Simulate multiple paths
forecast_paths <- matrix(NA, nrow=n_sim, ncol=h)
for(sim in 1:n_sim) {
level <- last_level
for(step in 1:h) {
error <- rnorm(1, 0, sd_error)
y_forecast <- level + error
level <- level + alpha * error  # Update level based on alpha
forecast_paths[sim, step] <- y_forecast
}
}
# Calculate prediction intervals
lower_prob <- (1 - prob) / 2
upper_prob <- 1 - lower_prob
return(list(
mean = colMeans(forecast_paths),
median = apply(forecast_paths, 2, median),
lower = apply(forecast_paths, 2, quantile, lower_prob),
upper = apply(forecast_paths, 2, quantile, upper_prob),
lower_50 = apply(forecast_paths, 2, quantile, 0.25),
upper_50 = apply(forecast_paths, 2, quantile, 0.75),
all_paths = forecast_paths
))
}
# Test different alpha values
alphas <- c(0, 0.1, 0.3, 0.7, 1.0)
results <- data.frame(time = 1:n, Y = Y)
# Store forecasts
forecasts <- list()
for(a in alphas) {
level_col <- paste0("level_alpha_", a)
levels <- exp_smooth(Y, a, true_level0)
results[[level_col]] <- levels
# Generate forecasts with prediction intervals
last_level <- levels[n]
forecasts[[as.character(a)]] <- simulate_forecast(last_level, a, h, sd_error, n_sim=1000, prob=0.90)
}
# Plotting
par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))
# Define colors
colors <- list("0" = "gray50", "0.1" = "blue", "0.3" = "green",
"0.7" = "orange", "1" = "red")
# Plot for each alpha
plot_alphas <- c(0, 0.1, 0.3, 1.0)
for(a in plot_alphas) {
# Extend x-axis to include forecast horizon
xlim_range <- c(1, n + h)
# Calculate y-axis limits including forecasts
forecast_data <- forecasts[[as.character(a)]]
ylim_range <- range(c(Y, results[, grep("level", names(results))],
forecast_data$lower, forecast_data$upper))
# Plot observed series
plot(1:n, Y, type = "l", pch = 20, col = "black", cex = 0.8,
xlab = "Time", ylab = "Value",
main = bquote("α = " ~ .(a) ~ " with 90% Prediction Interval"),
xlim = xlim_range,
ylim = ylim_range)
# Mark the large error
abline(v = 50, lty = 2, col = "darkred", lwd = 1.5)
abline(v = n, lty = 2, col = "gray30", lwd = 1)
text(n, ylim_range[1], "Forecast", pos = 4, col = "gray30", cex=0.8)
# Add level line
level_col <- paste0("level_alpha_", a)
lines(1:n, results[[level_col]], col = colors[[as.character(a)]], lwd = 2)
# Add forecast
forecast_times <- (n+1):(n+h)
# Add 90% prediction interval (outer, lighter shade)
polygon(c(forecast_times, rev(forecast_times)),
c(forecast_data$lower, rev(forecast_data$upper)),
col = adjustcolor(colors[[as.character(a)]], alpha.f = 0.15),
border = NA)
# Add 50% prediction interval (inner, darker shade)
polygon(c(forecast_times, rev(forecast_times)),
c(forecast_data$lower_50, rev(forecast_data$upper_50)),
col = adjustcolor(colors[[as.character(a)]], alpha.f = 0.3),
border = NA)
# Add median forecast
lines(forecast_times, forecast_data$median,
col = colors[[as.character(a)]], lwd = 2.5, lty = 1)
# Connect last level to first forecast
lines(c(n, n+1), c(results[[level_col]][n], forecast_data$median[1]),
col = colors[[as.character(a)]], lwd = 2.5, lty = 1)
# Add legend
legend("topright",
legend = c("Observed", "Fitted level", "Forecast median", "50% PI", "90% PI"),
col = c("black", colors[[as.character(a)]], colors[[as.character(a)]],
colors[[as.character(a)]], colors[[as.character(a)]]),
lwd = c(1, 2, 2.5, NA, NA),
lty = c(1, 1, 1, NA, NA),
pch = c(NA, NA, NA, 15, 15),
pt.cex = c(NA, NA, NA, 2, 2),
fill = c(NA, NA, NA,
adjustcolor(colors[[as.character(a)]], alpha.f = 0.3),
adjustcolor(colors[[as.character(a)]], alpha.f = 0.15)),
border = c(NA, NA, NA, NA, NA),
cex = 0.65,
bg = "white")
}
for(a in plot_alphas) {
# Extend x-axis to include forecast horizon
xlim_range <- c(1, n + h)
# Calculate y-axis limits including forecasts
forecast_data <- forecasts[[as.character(a)]]
ylim_range <- range(c(Y, results[, grep("level", names(results))],
forecast_data$lower, forecast_data$upper))
# Plot observed series
plot(1:n, Y, type = "l", pch = 20, col = "black", cex = 0.8,
xlab = "Time", ylab = "Value",
main = bquote("α = " ~ .(a) ~ " with 90% Prediction Interval"),
xlim = xlim_range,
ylim = ylim_range)
# Mark the large error
abline(v = 50, lty = 2, col = "darkred", lwd = 1.5)
abline(v = n, lty = 2, col = "gray30", lwd = 1)
text(n, ylim_range[1], "Forecast", pos = 4, col = "gray30", cex=0.8)
# Add level line
level_col <- paste0("level_alpha_", a)
lines(1:n, results[[level_col]], col = colors[[as.character(a)]], lwd = 2)
# Add forecast
forecast_times <- (n+1):(n+h)
# Add 90% prediction interval (outer, lighter shade)
polygon(c(forecast_times, rev(forecast_times)),
c(forecast_data$lower, rev(forecast_data$upper)),
col = adjustcolor(colors[[as.character(a)]], alpha.f = 0.15),
border = NA)
# Add 50% prediction interval (inner, darker shade)
polygon(c(forecast_times, rev(forecast_times)),
c(forecast_data$lower_50, rev(forecast_data$upper_50)),
col = adjustcolor(colors[[as.character(a)]], alpha.f = 0.3),
border = NA)
# Add median forecast
lines(forecast_times, forecast_data$median,
col = colors[[as.character(a)]], lwd = 2.5, lty = 1)
# Connect last level to first forecast
lines(c(n, n+1), c(results[[level_col]][n], forecast_data$median[1]),
col = colors[[as.character(a)]], lwd = 2.5, lty = 1)
# # Add legend
# legend("topright",
#        legend = c("Observed", "Fitted level", "Forecast median", "50% PI", "90% PI"),
#        col = c("black", colors[[as.character(a)]], colors[[as.character(a)]],
#                colors[[as.character(a)]], colors[[as.character(a)]]),
#        lwd = c(1, 2, 2.5, NA, NA),
#        lty = c(1, 1, 1, NA, NA),
#        pch = c(NA, NA, NA, 15, 15),
#        pt.cex = c(NA, NA, NA, 2, 2),
#        fill = c(NA, NA, NA,
#                 adjustcolor(colors[[as.character(a)]], alpha.f = 0.3),
#                 adjustcolor(colors[[as.character(a)]], alpha.f = 0.15)),
#        border = c(NA, NA, NA, NA, NA),
#        cex = 0.65,
#        bg = "white")
}
load("~/3-process-v2/data/Gift-v1.Rdata")
mydata
# EDA
summary(mydata)
mydata <- mydata[, list(Id, Date, Price)]
mydata[, Date:=ymd(Date)]
library(data.table)
library(CLVTools)
# EDA
summary(mydata)
mydata <- mydata[, list(Id, Date, Price)]
mydata[, Date:=ymd(Date)]
#Load necessary libraries
library(bayesplot)
library(readxl)
library(copula)
library(numDeriv)
library(stats)
library(ggplot2)
library(parallel)
library(data.table)
library(Matrix)  # Load the Matrix package for sparse matrices
library(CLVTools)
library(dplyr)
library(lubridate)
# EDA
summary(mydata)
mydata <- mydata[, list(Id, Date, Price)]
mydata[, Date:=ymd(Date)]
mydata[, Id:=as.numeric(Id)]
estimation.duration <- 104
#Create CLVdata Object
clv.data <- clvdata( mydata, date.format = "ymd", time.unit = "week",  estimation.split = estimation.duration,
name.id = "Id", name.date = "Date",name.price = "Price")
summary(clv.data)
# independent: pnbd, gam gam estimation
clv.all <- pnbd(clv.data)
cbs <- clv.all@cbs
clv.gam <- gg(clv.data)
cbs2 <- clv.gam@cbs
# Customer-By-Sufficient Statistics (CBS) matrix.
head(cbs)
head(cbs2)
# arrange everything in a data frame
data <- merge(cbs, cbs2, by = "Id") %>%
dplyr::select(-x.y) %>%  # Remove column "x.y"
rename(x = x.x, t_x = t.x, T = T.cal, m_x = Spending) %>%
mutate(Id = as.numeric(Id)) %>%
arrange(Id)  # Sort data by Id
head(data)
# Evaluation of the prediction with clvtool
dt.pred <- predict(clv.all, predict.spending = clv.gam,prediction.end=104)
df
spend_gam
# store in a dataframe
spend_gam <- data.frame( Id = data$Id, spend)
# expected spending amount
hype_gam <- opt_params
spend <- predict_spending (hype_gam, data$x , data$m_x)
# Evaluation of the prediction with clvtool
dt.pred <- predict(clv.all, predict.spending = clv.gam,prediction.end=104)
dt.pred
# select relevant data from predict
df_nb_trans <- data.frame(dt.pred[, list(Id, actual.x, CET,predicted.mean.spending,predicted.total.spending, actual.total.spending)])
# Merge clv tools prediction and our results
df <- merge( predict.nb, df_nb_trans, by = "Id", all.x = TRUE)
df_nb_trans
# Merge clv tools prediction and our results
df <- merge( predict.nb, df_nb_trans, by = "Id", all.x = TRUE)
# Merge clv tools prediction and our results
df <- df_nb_trans
head(df)
spend
df
# metrics
mae <- function(x, y){return(mean(abs(x - y)))}
rmse <- function(x, y){sqrt(mean((x - y)^2))}
# rmse from clv.tool PNBD + Gamma Gamma
mae(final_df$actual.total.spending,final_df$predicted.total.spending)
rmse(final_df$actual.total.spending,final_df$predicted.total.spending)
final_df$actual.total.spending
final_df<-df
# metrics
mae <- function(x, y){return(mean(abs(x - y)))}
rmse <- function(x, y){sqrt(mean((x - y)^2))}
# mae from code PNBD + Gamma Gamma
mae(final_df$actual.total.spending,final_df$pred.spend)
rmse(final_df$actual.total.spending,final_df$pred.spend)
final_df$actual.total.spending
final_df$predicted.total.spending
# rmse from clv.tool PNBD + Gamma Gamma
mae(final_df$actual.total.spending,final_df$predicted.total.spending)
# rmse from clv.tool PNBD + Gamma Gamma
mae(final_df$actual.total.spending,final_df$predicted.total.spending)
rmse(final_df$actual.total.spending,final_df$predicted.total.spending)
# Install and load required packages
# install.packages("dfms")
library(dfms)
# Optional: for data manipulation and visualization
# install.packages("ggplot2")
# install.packages("reshape2")
library(ggplot2)
library(reshape2)
set.seed(123)
# Parameters
n_series <- 50      # number of observed time series
n_time <- 200       # number of time periods
r <- 3              # number of common factors
p <- 2              # VAR lag order for factors
# VAR coefficient matrices
Phi1 <- matrix(c(0.5, 0.1, 0.0,
0.1, 0.4, 0.1,
0.0, 0.1, 0.3), r, r)
Phi2 <- matrix(c(0.2, 0.05, 0.0,
0.05, 0.2, 0.05,
0.0, 0.05, 0.15), r, r)
# Initialize factors
factors <- matrix(0, n_time, r)
factors[1,] <- rnorm(r)
factors[2,] <- rnorm(r)
# Generate factors with VAR(2) dynamics
for(t in 3:n_time) {
factors[t,] <- Phi1 %*% factors[t-1,] + Phi2 %*% factors[t-2,] + rnorm(r, sd = 0.5)
}
# Generate factor loadings (C matrix)
C <- matrix(runif(n_series * r, -1, 1), n_series, r)
?dfms
?DFM
# Install and load required packages
# install.packages("dfms")
library(dfms)
install.packages("dfms")
# Install and load required packages
# install.packages("dfms")
library(dfms)
?dfms
?DFM
setwd("~/GitHub/Forecasting")
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(CLVTools)
load("Gift-v1.Rdata")
clv.gift <- clvdata(mydata,
date.format="ymd",
time.unit = "week",
estimation.split = 156,
name.id = "Id",
name.date = "Date",
name.price = "Price")
plot(clv.gift)
# Remove all other covariates
covariates.dynamic<-covariates.dynamic[,c("Id", "Cov.Date")]
# (1) Holiday dummy for December and surrounding months
# Define which months should be considered as "holiday period"
covariates.dynamic[, holiday := ifelse(month(Cov.Date) %in% c(11, 12, 1), 1, 0)]
# Alternative: only December
# dt[, holiday := ifelse(month(Cov.Date) == 12, 1, 0)]
# (2) Fourier terms for dynamic regression
# Set K (number of Fourier pairs)
K <- 3  # You can adjust this
# Create time index t (starts at 0)
covariates.dynamic[, t := 0:(.N-1), by = Id]
# Generate Fourier terms for each k from 1 to K
for(k in 1:K) {
# Sine term
covariates.dynamic[, paste0("sin_", k) := sin(2 * pi * k * t / 52)]
# Cosine term
covariates.dynamic[, paste0("cos_", k) := cos(2 * pi * k * t / 52)]
}
# Check the result
head(covariates.dynamic, 20)
nam<-colnames(covariates.dynamic)[3:ncol(covariates.dynamic)]
clv.dynamic <- SetDynamicCovariates(
clv.data = clv.gift,
data.cov.life = covariates.dynamic,
data.cov.trans = covariates.dynamic,
names.cov.life =nam,
names.cov.trans = nam,
name.id = "Id",
name.date = "Cov.Date"
)
est.pnbd.static.K0 <- latentAttrition(
formula =~ holiday|holiday ,
family = pnbd,
data = clv.dynamic,
optimx.args = list(method = "Nelder-Mead"))
