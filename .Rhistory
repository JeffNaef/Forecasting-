#F_t=AF_{t-1} + u_t
##
# Extract model components
A <- fit$params$A          # VAR coefficients
Lambda <- fit$params$Lambda  # p x r
Sigma_u <- fit$params$Sigma_u    #
Sigma_epsilon <- fit$params$Sigma_epsilon    #
n_series <- nrow(Lambda)
r <- ncol(Lambda)
p <- fit$p  # VAR lag order
# Storage for simulations
Y_sim <- array(NA, dim = c(h, n_series, n_sim))
FT1<-predict(fit)$F_hat ## E[F_{T+1}|\mathcal{F}_T]
# Simulate from the DFM
for(sim in 1:n_sim) {
# Draw from factor T+1 by drawing from a Gaussian with N(E[F_{T+1}|\mathcal{F}_T], Sigma_u)
F_sim <- matrix(NA, h, r)
F_sim[1, ] <- FT1 + MASS::mvrnorm(1, mu = rep(0, r), Sigma = Sigma_u)
#Simulate from Y_{T+1}
Y_sim[1, , sim] <- Lambda %*% F_sim[1, ]+ MASS::mvrnorm(1, mu = rep(0, n_series), Sigma = diag(Sigma_epsilon))
# Simulate factors forward using VAR
for(t in 2:h) {
# Simulate Factors
F_sim[t, ] <- F_sim[t-1,] + MASS::mvrnorm(1, mu = rep(0, r), Sigma = Sigma_u)
# Simulate observations
Y_sim[t, , sim] <- Lambda %*% F_sim[t, ]+ MASS::mvrnorm(1, mu = rep(0, n_series), Sigma = diag(Sigma_epsilon))
}
}
# Calculate prediction intervals
alpha <- 1 - level
lower <- apply(Y_sim, c(1, 2), quantile, probs = alpha/2, na.rm = TRUE)
upper <- apply(Y_sim, c(1, 2), quantile, probs = 1 - alpha/2, na.rm = TRUE)
median_forecast <- apply(Y_sim, c(1, 2), median, na.rm = TRUE)
return(list(
median = median_forecast,
lower = lower,
upper = upper,
simulations = Y_sim
))
}
# Generate prediction intervals
set.seed(456)
pred_intervals <- generate_prediction_intervals(
fit = fit,
h = n_test,
n_sim = 1000,
level = 0.9
)
# Point forecasts (from predict method)
predictions <- predict(
object = fit,
h = n_test,
X_new = NULL
)
Y_pred <- predictions$X_hat
# # ============================================
# # 6. EVALUATE COVERAGE OF PREDICTION INTERVALS
# # ============================================
#
# # Check if true values fall within prediction intervals
# in_interval <- (Y_test >= pred_intervals$lower) & (Y_test <= pred_intervals$upper)
# coverage <- mean(in_interval, na.rm = TRUE)
# cat(sprintf("Empirical coverage of 90%% prediction intervals: %.1f%%\n", coverage * 100))
#
# # Coverage by horizon
# coverage_by_horizon <- rowMeans(in_interval, na.rm = TRUE)
# plot(1:n_test, coverage_by_horizon, type = "l",
#      ylim = c(0, 1),
#      main = "Prediction Interval Coverage by Horizon",
#      xlab = "Forecast Horizon", ylab = "Coverage Rate")
# abline(h = 0.90, col = "red", lty = 2)
# legend("bottomleft", legend = c("Empirical", "Nominal 90%"),
#        col = c("black", "red"), lty = c(1, 2))
# ============================================
# 7. VISUALIZE FORECASTS WITH PREDICTION INTERVALS
# ============================================
# Plot forecasts for a few series with prediction intervals
series_to_plot <- c(1, 5, 10)
par(mfrow = c(length(series_to_plot), 1), mar = c(4, 4, 3, 1))
for(i in series_to_plot) {
# Determine y-axis limits
y_range <- range(c(Y_train[, i], Y_test[, i],
pred_intervals$lower[, i], pred_intervals$upper[, i]),
na.rm = TRUE)
# Plot training data
plot(1:n_train, Y_train[, i], type = "l",
xlim = c(1, n_train + n_test),
ylim = y_range,
main = paste("Series", i, "- Forecasts with 90% Prediction Intervals"),
xlab = "Time", ylab = "Value", col = "gray50")
# Add forecast period separator
abline(v = n_train, col = "gray30", lty = 3, lwd = 1.5)
# Add prediction interval as shaded region
time_forecast <- (n_train+1):(n_train+n_test)
polygon(c(time_forecast, rev(time_forecast)),
c(pred_intervals$lower[, i], rev(pred_intervals$upper[, i])),
col = rgb(1, 0, 0, 0.2), border = NA)
# Add actual test values
lines(time_forecast, Y_test[, i], col = "black", lwd = 2)
# Add point forecast (median or mean)
lines(time_forecast, pred_intervals$median[, i], col = "red", lwd = 2, lty = 1)
# Add legend
legend("topleft",
legend = c("Training Data", "True Values", "Median Forecast", "90% PI"),
col = c("gray50", "black", "red", rgb(1, 0, 0, 0.2)),
lty = c(1, 1, 1, 1), lwd = c(1, 2, 2, 10),
cex = 0.7, bg = "white")
}
par(mfrow = c(1, 1))
# ============================================
# 8. ADDITIONAL DIAGNOSTICS
# ============================================
# Plot prediction interval width over time
pi_width <- pred_intervals$upper - pred_intervals$lower
mean_width_by_horizon <- rowMeans(pi_width)
plot(1:n_test, mean_width_by_horizon, type = "l",
main = "Average Prediction Interval Width by Horizon",
xlab = "Forecast Horizon", ylab = "Average PI Width", lwd = 2)
# Distribution of interval widths for a specific horizon
hist(pi_width[1, ], breaks = 30,
main = "Distribution of PI Widths at h=1",
xlab = "Prediction Interval Width",
col = "lightblue", border = "white")
# ============================================
# 9. COMPARE POINT FORECASTS
# ============================================
# Compare prediction methods
# Method 1: predict() function (conditional expectation)
# Method 2: Median from simulations
comparison_rmse <- data.frame(
Horizon = 1:n_test,
Predict_Method = sqrt(colMeans((Y_test - Y_pred)^2, na.rm = TRUE)),
Simulation_Median = sqrt(colMeans((Y_test - pred_intervals$median)^2, na.rm = TRUE))
)
# Plot forecasts for a few series with prediction intervals
series_to_plot <- c(1, 5, 10)
par(mfrow = c(length(series_to_plot), 1), mar = c(4, 4, 3, 1))
for(i in series_to_plot) {
# Determine y-axis limits
y_range <- range(c(Y_train[, i], Y_test[, i],
pred_intervals$lower[, i], pred_intervals$upper[, i]),
na.rm = TRUE)
# Plot training data
plot(1:n_train, Y_train[, i], type = "l",
xlim = c(1, n_train + n_test),
ylim = y_range,
main = paste("Series", i, "- Forecasts with 90% Prediction Intervals"),
xlab = "Time", ylab = "Value", col = "gray50")
# Add forecast period separator
abline(v = n_train, col = "gray30", lty = 3, lwd = 1.5)
# Add prediction interval as shaded region
time_forecast <- (n_train+1):(n_train+n_test)
polygon(c(time_forecast, rev(time_forecast)),
c(pred_intervals$lower[, i], rev(pred_intervals$upper[, i])),
col = rgb(1, 0, 0, 0.2), border = NA)
# Add actual test values
lines(time_forecast, Y_test[, i], col = "black", lwd = 2)
# Add point forecast (median or mean)
lines(time_forecast, pred_intervals$median[, i], col = "red", lwd = 2, lty = 1)
# Add legend
legend("topleft",
legend = c("Training Data", "True Values", "Median Forecast", "90% PI"),
col = c("gray50", "black", "red", rgb(1, 0, 0, 0.2)),
lty = c(1, 1, 1, 1), lwd = c(1, 2, 2, 10),
cex = 0.7, bg = "white")
}
par(mfrow = c(1, 1))
# Example: Probability that Series 1 exceeds a threshold at h=1
threshold <- 0.5
prob_exceed <- mean(pred_intervals$simulations[1, 1, ] > threshold)
cat(sprintf("\nP(Series 1 > %.2f at h=1) = %.3f\n", threshold, prob_exceed))
# Predictive density for Series 1 at h=1
hist(pred_intervals$simulations[1, 1, ], breaks = 50, freq = FALSE,
main = "Predictive Density for Series 1 at h=1",
xlab = "Value", col = "lightblue", border = "white")
abline(v = Y_test[1, 1], col = "red", lwd = 2, lty = 2)
legend("topright", legend = "True Value", col = "red", lty = 2, lwd = 2)
# Create a fan chart showing multiple quantiles
create_fan_chart <- function(series_idx, pred_intervals, Y_train, Y_test, n_train) {
quantiles <- c(0.1, 0.25, 0.5, 0.75, 0.9)
colors <- c(rgb(0, 0, 1, 0.1), rgb(0, 0, 1, 0.2),
rgb(0, 0, 1, 0.3), rgb(0, 0, 1, 0.2), rgb(0, 0, 1, 0.1))
# Calculate quantiles
q_forecasts <- apply(pred_intervals$simulations[, series_idx, ], 1,
quantile, probs = quantiles)
time_forecast <- (n_train+1):(n_train+nrow(q_forecasts))
# Plot
y_range <- range(c(Y_train[, series_idx], Y_test[, series_idx], q_forecasts),
na.rm = TRUE)
plot(1:n_train, Y_train[, series_idx], type = "l",
xlim = c(1, n_train + nrow(q_forecasts)),
ylim = y_range,
main = paste("Fan Chart for Series", series_idx),
xlab = "Time", ylab = "Value", lwd = 1.5)
abline(v = n_train, col = "gray", lty = 3)
# Add shaded regions
for(i in 1:(length(quantiles)-1)) {
polygon(c(time_forecast, rev(time_forecast)),
c(q_forecasts[i, ], rev(q_forecasts[length(quantiles)-i+1, ])),
col = colors[i], border = NA)
}
# Add median
lines(time_forecast, q_forecasts[3, ], col = "blue", lwd = 2)
# Add actual values
lines(time_forecast, Y_test[, series_idx], col = "red", lwd = 2)
legend("topleft",
legend = c("Historical", "Actual", "Median Forecast", "10-90%", "25-75%"),
col = c("black", "red", "blue", colors[1], colors[2]),
lty = c(1, 1, 1, 1, 1), lwd = c(1.5, 2, 2, 10, 10),
cex = 0.8)
}
# Create fan chart for Series 1
create_fan_chart(1, pred_intervals, Y_train, Y_test, n_train)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
fig.width = 10,
fig.height = 6
)
# Install packages if needed
# install.packages(c("sparseDFM", "doSNOW", "fpp3", "forecast",
#                    "patchwork", "dCovTS", "ggplot2", "reshape2", "MASS"))
library(sparseDFM)
library(doSNOW)
library(fpp3)
library(forecast)
library(patchwork)
library(dCovTS)
library(ggplot2)
library(reshape2)
library(MASS)
# Install packages if needed
# install.packages(c("sparseDFM", "doSNOW", "fpp3", "forecast",
#                    "patchwork", "dCovTS", "ggplot2", "reshape2", "MASS"))
library(sparseDFM)
library(doSNOW)
library(fpp3)
library(forecast)
library(patchwork)
library(dCovTS)
library(ggplot2)
library(reshape2)
library(MASS)
set.seed(123)
# Model dimensions
n_series <- 50      # number of observed time series
n_time <- 200       # number of time periods
r <- 3              # number of common factors
p <- 1              # VAR lag order for factors (VAR(1))
set.seed(123)
# Model dimensions
n_series <- 50      # number of observed time series
n_time <- 200       # number of time periods
r <- 3              # number of common factors
p <- 1              # VAR lag order for factors (VAR(1))
# VAR coefficient matrix for VAR(1)
Phi1 <- matrix(c(0.5, 0.1, 0.0,
0.1, 0.4, 0.1,
0.0, 0.1, 0.3), r, r)
print("VAR(1) coefficient matrix Phi1:")
print(Phi1)
# Initialize factors
factors <- matrix(0, n_time, r)
factors[1,] <- rnorm(r)
# Generate factors with VAR(1) dynamics: F_t = Phi1 * F_{t-1} + u_t
for(t in 2:n_time) {
factors[t,] <- Phi1 %*% factors[t-1,] + rnorm(r, sd = 0.5)
}
par(mfrow = c(r, 1), mar = c(3, 4, 2, 1))
for(i in 1:r) {
plot(factors[, i], type = "l", main = paste("Factor", i),
ylab = "Value", xlab = "Time", col = "steelblue", lwd = 1.5)
grid()
}
par(mfrow = c(1, 1))
# Generate factor loadings (Lambda matrix)
C <- matrix(runif(n_series * r, -1, 1), n_series, r)
# Generate observed data: y_t = C * F_t + e_t
idiosyncratic_error <- matrix(rnorm(n_series * n_time, sd = 0.3),
n_time, n_series)
data_matrix <- factors %*% t(C) + idiosyncratic_error
# Take first differences for stationarity
data_diff <- diff(data_matrix)
# Name the series
colnames(data_diff) <- paste0("Series", 1:n_series)
cat("Data dimensions (after differencing):", dim(data_diff), "\n")
cat("Number of observations:", nrow(data_diff), "\n")
cat("Number of series:", ncol(data_diff), "\n")
series_to_show <- c(1, 5, 10, 15)
par(mfrow = c(length(series_to_show), 1), mar = c(3, 4, 2, 1))
for(i in series_to_show) {
plot(data_diff[, i], type = "l", main = paste("Series", i),
ylab = "Value", xlab = "Time", col = "darkgreen", lwd = 1)
grid()
}
par(mfrow = c(1, 1))
Y <- data_diff
n_train <- 180
n_test <- nrow(Y) - n_train
Y_train <- Y[1:n_train, ]
Y_test <- Y[(n_train+1):nrow(Y), ]
cat("Training set size:", n_train, "\n")
cat("Test set size:", n_test, "\n")
# Use tuneFactors to identify optimal number of factors
factor_selection <- tuneFactors(Y_train)
print(factor_selection)
# Estimate sparse DFM
fit <- sparseDFM(
X = Y_train,
r = 3              # number of factors
)
# View model summary
summary(fit)
cor(Y)
set.seed(123)
# Model dimensions
n_series <- 50      # number of observed time series
n_time <- 200       # number of time periods
r <- 3              # number of common factors
p <- 1              # VAR lag order for factors (VAR(1))
plot(fit, type = "factor")
plot(fit, type = "residual")
plot(fit, type = "loading.heatmap")
generate_prediction_intervals <- function(fit, h, n_sim = 1000, level = 0.95) {
# Extract model components
# Y_t = Lambda * F_t + epsilon_t
# F_t = A * F_{t-1} + u_t
A <- fit$params$A                    # VAR coefficients
Lambda <- fit$params$Lambda          # n_series x r
Sigma_u <- fit$params$Sigma_u        # r x r
Sigma_epsilon <- fit$params$Sigma_epsilon  # n_series x n_series (diagonal)
n_series <- nrow(Lambda)
r <- ncol(Lambda)
p <- fit$p  # VAR lag order
# Storage for simulations
Y_sim <- array(NA, dim = c(h, n_series, n_sim))
# Get E[F_{T+1} | F_T]
FT1 <- predict(fit)$F_hat
# Simulate from the DFM
for(sim in 1:n_sim) {
# Initialize factor simulations
F_sim <- matrix(NA, h, r)
# Draw F_{T+1} ~ N(E[F_{T+1}|F_T], Sigma_u)
F_sim[1, ] <- FT1 + mvrnorm(1, mu = rep(0, r), Sigma = Sigma_u)
# Draw Y_{T+1} | F_{T+1}
Y_sim[1, , sim] <- Lambda %*% F_sim[1, ] +
mvrnorm(1, mu = rep(0, n_series), Sigma = diag(Sigma_epsilon))
# Simulate forward h-1 more steps
for(t in 2:h) {
# Simulate F_t from VAR(1): F_t = A * F_{t-1} + u_t
F_sim[t, ] <- A %*% F_sim[t-1, ] +
mvrnorm(1, mu = rep(0, r), Sigma = Sigma_u)
# Simulate Y_t | F_t
Y_sim[t, , sim] <- Lambda %*% F_sim[t, ] +
mvrnorm(1, mu = rep(0, n_series), Sigma = diag(Sigma_epsilon))
}
}
# Calculate prediction intervals
alpha <- 1 - level
lower <- apply(Y_sim, c(1, 2), quantile, probs = alpha/2, na.rm = TRUE)
upper <- apply(Y_sim, c(1, 2), quantile, probs = 1 - alpha/2, na.rm = TRUE)
median_forecast <- apply(Y_sim, c(1, 2), median, na.rm = TRUE)
return(list(
median = median_forecast,
lower = lower,
upper = upper,
simulations = Y_sim
))
}
set.seed(456)
# Generate 90% prediction intervals
pred_intervals <- generate_prediction_intervals(
fit = fit,
h = n_test,
n_sim = 1000,
level = 0.90
)
# Get point forecasts from predict method
predictions <- predict(
object = fit,
h = n_test,
X_new = NULL
)
Y_pred <- predictions$X_hat
cat("Prediction intervals generated successfully!\n")
cat("Forecast horizon:", n_test, "periods\n")
cat("Number of simulations:", 1000, "\n")
# Check if true values fall within prediction intervals
in_interval <- (Y_test >= pred_intervals$lower) & (Y_test <= pred_intervals$upper)
coverage <- mean(in_interval, na.rm = TRUE)
cat(sprintf("Empirical coverage of 90%% prediction intervals: %.1f%%\n",
coverage * 100))
set.seed(456)
# Generate 90% prediction intervals
pred_intervals <- generate_prediction_intervals(
fit = fit,
h = n_test,
n_sim = 1000,
level = 0.80
)
# Get point forecasts from predict method
predictions <- predict(
object = fit,
h = n_test,
X_new = NULL
)
Y_pred <- predictions$X_hat
cat("Prediction intervals generated successfully!\n")
cat("Forecast horizon:", n_test, "periods\n")
cat("Number of simulations:", 1000, "\n")
# Check if true values fall within prediction intervals
in_interval <- (Y_test >= pred_intervals$lower) & (Y_test <= pred_intervals$upper)
coverage <- mean(in_interval, na.rm = TRUE)
cat(sprintf("Empirical coverage of 90%% prediction intervals: %.1f%%\n",
coverage * 100))
coverage_by_horizon <- rowMeans(in_interval, na.rm = TRUE)
plot(1:n_test, coverage_by_horizon, type = "l", lwd = 2,
ylim = c(0, 1), col = "steelblue",
main = "Prediction Interval Coverage by Horizon",
xlab = "Forecast Horizon", ylab = "Coverage Rate")
abline(h = 0.90, col = "red", lty = 2, lwd = 2)
grid()
legend("bottomleft", legend = c("Empirical", "Nominal 90%"),
col = c("steelblue", "red"), lty = c(1, 2), lwd = 2)
# Plot forecasts for selected series with prediction intervals
series_to_plot <- c(1, 5, 10)
par(mfrow = c(length(series_to_plot), 1), mar = c(4, 4, 3, 1))
for(i in series_to_plot) {
# Determine y-axis limits
y_range <- range(c(Y_train[, i], Y_test[, i],
pred_intervals$lower[, i], pred_intervals$upper[, i]),
na.rm = TRUE)
# Plot training data
plot(1:n_train, Y_train[, i], type = "l",
xlim = c(1, n_train + n_test),
ylim = y_range,
main = paste("Series", i, "- Forecasts with 90% Prediction Intervals"),
xlab = "Time", ylab = "Value", col = "gray50", lwd = 1.5)
# Add forecast period separator
abline(v = n_train, col = "gray30", lty = 3, lwd = 2)
# Add prediction interval as shaded region
time_forecast <- (n_train+1):(n_train+n_test)
polygon(c(time_forecast, rev(time_forecast)),
c(pred_intervals$lower[, i], rev(pred_intervals$upper[, i])),
col = rgb(1, 0, 0, 0.2), border = NA)
# Add actual test values
lines(time_forecast, Y_test[, i], col = "black", lwd = 2)
# Add median forecast
lines(time_forecast, pred_intervals$median[, i], col = "red", lwd = 2, lty = 1)
grid()
# Add legend
legend("topleft",
legend = c("Training Data", "True Values", "Median Forecast", "90% PI"),
col = c("gray50", "black", "red", rgb(1, 0, 0, 0.2)),
lty = c(1, 1, 1, 1), lwd = c(1.5, 2, 2, 10),
cex = 0.8, bg = "white")
}
par(mfrow = c(1, 1))
# Analyze prediction interval width
pi_width <- pred_intervals$upper - pred_intervals$lower
mean_width_by_horizon <- rowMeans(pi_width)
plot(1:n_test, mean_width_by_horizon, type = "l", lwd = 2, col = "darkblue",
main = "Average Prediction Interval Width by Horizon",
xlab = "Forecast Horizon", ylab = "Average PI Width")
grid()
# Example: Probability that Series 1 exceeds a threshold at h=1
threshold <- 0.5
prob_exceed <- mean(pred_intervals$simulations[1, 1, ] > threshold)
cat(sprintf("P(Series 1 > %.2f at h=1) = %.3f\n", threshold, prob_exceed))
# Visualize predictive density
hist(pred_intervals$simulations[1, 1, ], breaks = 50, freq = FALSE,
main = "Predictive Density for Series 1 at h=1",
xlab = "Value", col = "lightblue", border = "white",
xlim = range(c(pred_intervals$simulations[1, 1, ], Y_test[1, 1])))
abline(v = Y_test[1, 1], col = "red", lwd = 3, lty = 2)
abline(v = threshold, col = "darkgreen", lwd = 2, lty = 3)
legend("topright",
legend = c("True Value", "Threshold"),
col = c("red", "darkgreen"), lty = c(2, 3), lwd = c(3, 2))
# Create a fan chart showing multiple quantiles
series_idx <- 1
quantiles <- c(0.05, 0.25, 0.50, 0.75, 0.95)
q_forecasts <- t(apply(pred_intervals$simulations[, series_idx, ], 1,
quantile, probs = quantiles))
time_all <- 1:(n_train + n_test)
time_forecast <- (n_train+1):(n_train+n_test)
# Plot
y_range <- range(c(Y_train[, series_idx], Y_test[, series_idx], q_forecasts),
na.rm = TRUE)
plot(1:n_train, Y_train[, series_idx], type = "l", lwd = 1.5,
xlim = range(time_all), ylim = y_range,
main = paste("Fan Chart for Series", series_idx),
xlab = "Time", ylab = "Value", col = "black")
abline(v = n_train, col = "gray", lty = 3, lwd = 2)
# Add shaded regions for different quantiles
polygon(c(time_forecast, rev(time_forecast)),
c(q_forecasts[, 1], rev(q_forecasts[, 5])),
col = rgb(0, 0, 1, 0.1), border = NA)
polygon(c(time_forecast, rev(time_forecast)),
c(q_forecasts[, 2], rev(q_forecasts[, 4])),
col = rgb(0, 0, 1, 0.2), border = NA)
# Add median
lines(time_forecast, q_forecasts[, 3], col = "blue", lwd = 2)
# Add actual values
lines(time_forecast, Y_test[, series_idx], col = "red", lwd = 2)
legend("topleft",
legend = c("Historical", "Actual", "Median Forecast", "5-95%", "25-75%"),
col = c("black", "red", "blue", rgb(0, 0, 1, 0.1), rgb(0, 0, 1, 0.2)),
lty = 1, lwd = c(1.5, 2, 2, 10, 10), cex = 0.8)
grid()
cor(data_matrix)
