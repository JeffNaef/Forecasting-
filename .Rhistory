}
pred_mean <- apply(boot_preds, 1, mean)
alpha <- .1
pred_q_upper <- apply(boot_preds, 1, function(x) quantile(x, probs = 1- alpha/2))
pred_q_lower <- apply(boot_preds, 1, function(x) quantile(x, probs = alpha/2))
plot(y, type="l", col="white", main="Bootstrap Forecasts with 90% Prediction Band",
ylab="y", xlab="t", ylim=c(-5,5))
lines(y[1:n_train])
# plot bootstrap paths
for(b in 1:B){
lines(n_train + 1:h, boot_preds[,b], col=rgb(0,0,0,alpha=0.05))
}
# mean forecast
lines(n_train + 1:h, pred_mean, col="blue", lwd=2)
# quantile forecast band
lines(n_train + 1:h, pred_q_upper, col="red", lwd=2, lty=2)
lines(n_train + 1:h, pred_q_lower, col="red", lwd=2, lty=2)
# shaded area for prediction band
polygon(c(n_train + 1:h, rev(n_train + 1:h)),
c(pred_q_upper, rev(pred_q_lower)),
col=rgb(1,0,0,alpha=0.2), border=NA)
legend("topleft",
legend=c("Observed","Mean forecast","90% Prediction Band"),
col=c("black","blue","red"), lty=c(1,1,2), lwd=c(1,2,2), bty="n")
rmse_mean <- sqrt(mean((y_test - pred_mean)^2))
rmse_q_upper <- sqrt(mean((y_test - pred_q_upper)^2))
# quantile score on predicted quantile
mean_qs_upper <- mean(
(1-alpha/2 - 1)*(y_test - pred_q_upper)*(y_test < pred_q_upper) +
(1-alpha/2)*(y_test - pred_q_upper)*(y_test >= pred_q_upper)
)
# quantile score on mean
mean_qs_mean <- mean(
(0.5 - 1)*(y_test - pred_mean)*(y_test < pred_mean) +
(0.5)*(y_test - pred_mean)*(y_test >= pred_mean)
)
# print results
cat(paste0("RMSE on mean forecast: ", round(rmse_mean,4), "\n"))
cat(paste0("RMSE on 95% quantile forecast: ", round(rmse_q_upper,4), "\n"))
# print results
cat(paste0("RMSE on mean forecast: ", round(rmse_mean,4), "\n"))
cat(paste0("Mean Quantile Score on mean forecast: ", round(mean_qs_mean,4), "\n"))
cat(paste0("RMSE on 95% quantile forecast: ", round(rmse_q_upper,4), "\n"))
cat(paste0("Mean Quantile Score on 5% quantile forecast: ", round(mean_qs_upper,4), "\n"))
# quantile score on mean
mean_qs_mean <- mean(
(0.95 - 1)*(y_test - pred_mean)*(y_test < pred_mean) +
(0.95)*(y_test - pred_mean)*(y_test >= pred_mean)
)
mean_qs_mean
# quantile score on mean
mean_qs_mean <- mean(
(0.5 - 1)*(y_test - pred_mean)*(y_test < pred_mean) +
(0.5)*(y_test - pred_mean)*(y_test >= pred_mean)
)
mean_qs_mean
rm(list=ls())
n <- 200
phi <- 0.6
theta <- 0.3
sigma <- 1
y <- arima.sim(n = n, list(ar = phi, ma = theta), sd = sigma)
p_train <- 0.7
n_train <- floor(n * p_train)
y_train <- y[1:n_train]
y_test <- y[(n_train+1):n]
h <- length(y_test)
fit <- Arima(y_train, order = c(1,0,1), include.mean = FALSE)
B <- 500  # number of bootstrap paths
boot_preds <- matrix(NA, nrow = h, ncol = B)
for(b in 1:B){
boot_path <- simulate(fit, nsim = h, bootstrap = TRUE)
boot_preds[,b] <- boot_path
}
pred_mean <- apply(boot_preds, 1, mean)
alpha <- .1
pred_q_upper <- apply(boot_preds, 1, function(x) quantile(x, probs = 1- alpha/2))
pred_q_lower <- apply(boot_preds, 1, function(x) quantile(x, probs = alpha/2))
plot(y, type="l", col="white", main="Bootstrap Forecasts with 90% Prediction Band",
ylab="y", xlab="t", ylim=c(-5,5))
lines(y[1:n_train])
# plot bootstrap paths
for(b in 1:B){
lines(n_train + 1:h, boot_preds[,b], col=rgb(0,0,0,alpha=0.05))
}
# mean forecast
lines(n_train + 1:h, pred_mean, col="blue", lwd=2)
# quantile forecast band
lines(n_train + 1:h, pred_q_upper, col="red", lwd=2, lty=2)
lines(n_train + 1:h, pred_q_lower, col="red", lwd=2, lty=2)
# shaded area for prediction band
polygon(c(n_train + 1:h, rev(n_train + 1:h)),
c(pred_q_upper, rev(pred_q_lower)),
col=rgb(1,0,0,alpha=0.2), border=NA)
legend("topleft",
legend=c("Observed","Mean forecast","90% Prediction Band"),
col=c("black","blue","red"), lty=c(1,1,2), lwd=c(1,2,2), bty="n")
rmse_mean <- sqrt(mean((y_test - pred_mean)^2))
rmse_q_upper <- sqrt(mean((y_test - pred_q_upper)^2))
# rmse on predicted mean
rmse_mean <- sqrt(mean((y_test - pred_mean)^2))
rmse_q_upper <- sqrt(mean((y_test - pred_q_upper)^2))
# quantile score on predicted quantile
mean_qs_upper <- mean(
(1-alpha/2 - 1)*(y_test - pred_q_upper)*(y_test < pred_q_upper) +
(1-alpha/2)*(y_test - pred_q_upper)*(y_test >= pred_q_upper)
)
# quantile score on mean
mean_qs_mean <- mean(
(0.5 - 1)*(y_test - pred_mean)*(y_test < pred_mean) +
(0.5)*(y_test - pred_mean)*(y_test >= pred_mean)
)
# print results
cat(paste0("RMSE on mean forecast: ", round(rmse_mean,4), "\n"))
cat(paste0("Mean Quantile Score on mean forecast: ", round(mean_qs_mean,4), "\n"))
cat(paste0("RMSE on 95% quantile forecast: ", round(rmse_q_upper,4), "\n"))
cat(paste0("Mean Quantile Score on 95% quantile forecast: ", round(mean_qs_upper,4), "\n"))
n <- 200
phi <- 0.6
theta <- 0.3
sigma <- 1
y <- arima.sim(n = n, list(ar = phi, ma = theta), sd = sigma)
p_train <- 0.7
n_train <- floor(n * p_train)
y_train <- y[1:n_train]
y_test <- y[(n_train+1):n]
h <- length(y_test)
fit <- Arima(y_train, order = c(1,0,1), include.mean = FALSE)
B <- 500  # number of bootstrap paths
boot_preds <- matrix(NA, nrow = h, ncol = B)
for(b in 1:B){
boot_path <- simulate(fit, nsim = h, bootstrap = TRUE)
boot_preds[,b] <- boot_path
}
pred_mean <- apply(boot_preds, 1, mean)
alpha <- .1
pred_q_upper <- apply(boot_preds, 1, function(x) quantile(x, probs = 1- alpha/2))
pred_q_lower <- apply(boot_preds, 1, function(x) quantile(x, probs = alpha/2))
plot(y, type="l", col="white", main="Bootstrap Forecasts with 90% Prediction Band",
ylab="y", xlab="t", ylim=c(-5,5))
lines(y[1:n_train])
# plot bootstrap paths
for(b in 1:B){
lines(n_train + 1:h, boot_preds[,b], col=rgb(0,0,0,alpha=0.05))
}
# mean forecast
lines(n_train + 1:h, pred_mean, col="blue", lwd=2)
# quantile forecast band
lines(n_train + 1:h, pred_q_upper, col="red", lwd=2, lty=2)
lines(n_train + 1:h, pred_q_lower, col="red", lwd=2, lty=2)
# shaded area for prediction band
polygon(c(n_train + 1:h, rev(n_train + 1:h)),
c(pred_q_upper, rev(pred_q_lower)),
col=rgb(1,0,0,alpha=0.2), border=NA)
# mean forecast
lines(n_train + 1:h, pred_mean, col="blue", lwd=2)
legend("topleft",
legend=c("Observed","Mean forecast","90% Prediction Band"),
col=c("black","blue","red"), lty=c(1,1,2), lwd=c(1,2,2), bty="n")
# rmse on predicted mean
rmse_mean <- sqrt(mean((y_test - pred_mean)^2))
rmse_q_upper <- sqrt(mean((y_test - pred_q_upper)^2))
# quantile score on predicted quantile
mean_qs_upper <- mean(
(1-alpha/2 - 1)*(y_test - pred_q_upper)*(y_test < pred_q_upper) +
(1-alpha/2)*(y_test - pred_q_upper)*(y_test >= pred_q_upper)
)
# quantile score on mean
mean_qs_mean <- mean(
(0.5 - 1)*(y_test - pred_mean)*(y_test < pred_mean) +
(0.5)*(y_test - pred_mean)*(y_test >= pred_mean)
)
# print results
cat(paste0("RMSE on mean forecast: ", round(rmse_mean,4), "\n"))
cat(paste0("Mean Quantile Score on mean forecast: ", round(mean_qs_mean,4), "\n"))
cat(paste0("RMSE on 95% quantile forecast: ", round(rmse_q_upper,4), "\n"))
cat(paste0("Mean Quantile Score on 95% quantile forecast: ", round(mean_qs_upper,4), "\n"))
a=c(1,3,5,9,9,11,13,13,18,20)
quantile(a)
?quantile
a=c(1,3,5,9,9,11,13,13,18,20)
quantile(a)
a=c(2,3,25,20,22,19,25,20,22,26)
quantile(a)
19.25 - 1.5 * (5)
x=c(1,2,3,5,3,2,1,22,54,60,35)
plot(density(x))
x=c(1,2,3,5,3,2,1,15,17,22,54,60,35)
plot(density(x))
median(x)
mean(x)
abline(v=median(x), col="red")
abline(v=mean(x), col="green")
rm(list=ls())
# Install and load required packages
# install.packages("dCovTS")
library(dCovTS)
# Theoretical distance correlation formula from Székely et al.
# MEASURING AND TESTING DEPENDENCE BY CORRELATION OF DISTANCES
theoretical_dcor <- function(rho) {
numerator <- rho * asin(rho) + sqrt(1 - rho^2) - rho * asin(rho / 2) - sqrt(4 - rho^2) + 1
denominator <- 1 + pi/3 - sqrt(3)
return(sqrt(numerator / denominator))
}
rho = 0
sqrt(1 - rho^2) - rho * asin(rho / 2)
sqrt(4 - rho^2)
+ 1
rho * asin(rho) + sqrt(1 - rho^2) - rho * asin(rho / 2) - sqrt(4 - rho^2) + 1
rm(list=ls())
# Install and load required packages
# install.packages("dCovTS")
library(dCovTS)
# Theoretical distance correlation formula from Székely et al.
# MEASURING AND TESTING DEPENDENCE BY CORRELATION OF DISTANCES
theoretical_dcor <- function(rho) {
# rho = 0
numerator <- rho * asin(rho) + sqrt(1 - rho^2) - rho * asin(rho / 2) - sqrt(4 - rho^2) + 1
denominator <- 1 + pi/3 - sqrt(3)
return(sqrt(numerator / denominator))
}
# empirical autocovariance
empirical_autocov <- function(x, lag.max = 20) {
n <- length(x)
x_bar <- mean(x)
sapply(0:lag.max, function(h) {
sum((x[1:(n-h)] - x_bar)*(x[(1+h):n] - x_bar)) / n
})
}
# Function to compute empirical autocorrelation manually
empirical_autocor <- function(x, lag.max = 20) {
acov <- empirical_autocov(x, lag.max)
acov / acov[1]
}
# Theoretical distance correlation for standard normals (Székely et al. 2007)
theoretical_dcor_normal <- function(rho) {
# rho = correlation
(rho * asin(rho) + sqrt(1 - rho^2) -  rho * asin(rho/2) - sqrt(4 - rho^2) + 1) /
(1 + pi/3 - sqrt(3))
}
n <- 500
sigma_wn <- 5
X_wn <- rnorm(n, mean = 0, sd = sigma_wn)
# Plot the time series
plot(X_wn, type = "l", main = "White Noise", ylab = "X_t")
# Compute manual autocovariance and autocorrelation
lag_max <- 20
gamma_wn <- empirical_autocov(X_wn, lag_max)
rho_wn <- empirical_autocor(X_wn, lag_max)
# Compare with acf()
acf_wn = acf(X_wn, lag.max = lag_max, main = "ACF White Noise", plot = TRUE)
all.equal(as.numeric(acf_wn$acf), rho_wn)
# Theoretical ACF for white noise
rho_theo_wn <- c(1, rep(0, lag_max))
# Plot: empirical vs theoretical ACF
plot(0:lag_max, rho_wn, type="b", pch=16, col="red",
ylim=c(-0.5,1), xlab="Lag", ylab="Autocorrelation",
main="White Noise: Empirical vs Theoretical ACF")
lines(0:lag_max, rho_theo_wn, type="b", lty=2, pch=1, col="blue")
legend("topright", legend=c("Empirical", "Theoretical"), col=c("red","blue"),
pch=c(16,1), lty=c(1,2), bty="n")
#----------------------------
# Distance correlation
#----------------------------
library(energy)
dcor_manual <- function(x, lag.max = 20) {
n <- length(x)
sapply(0:lag.max, function(h) {
if(h == 0) return(1)
energy::dcor(x[1:(n-h)], x[(1+h):n])
})
}
dcor_wn <- dcor_manual(X_wn, lag_max)
# compare with ADCF from dCovTS
dcor_wn_2 = ADCF(X_wn, MaxLag = lag_max)
all.equal(dcor_wn, as.vector(dcor_wn_2))
# Theoretical distance correlation: WN is i.i.d. => rho=0 for lag>0
dcor_theo <- sapply(0:lag_max, function(h) if(h==0) 1 else theoretical_dcor_normal(0))
# Plot: empirical vs theoretical distance correlation
plot(0:lag_max, dcor_wn, type="b", pch=16, col="red",
ylim=c(0,1), xlab="Lag", ylab="Distance Correlation",
main="White Noise: Empirical vs Theoretical Distance Correlation")
lines(0:lag_max, dcor_theo, type="b", lty=2, pch=1, col="blue")
legend("topright", legend=c("Empirical", "Theoretical"), col=c("red","blue"),
pch=c(16,1), lty=c(1,2), bty="n")
phi <- 0.7
sigma_ar1 <- 2
n <- 500
eps_ar1 <- rnorm(n, 0, sigma_ar1)
X_ar1 <- numeric(n)
# Set first observation from stationary distribution
X_ar1[1] <- rnorm(1, mean = 0, sd = sigma_ar1 / sqrt(1 - phi^2))
# Generate the rest
for(t in 2:n) X_ar1[t] <- phi * X_ar1[t-1] + eps_ar1[t]
# Plot time series
plot(X_ar1, type="l", main="AR(1) Process", ylab="X_t")
# Empirical autocovariance and autocorrelation
gamma_ar1 <- empirical_autocov(X_ar1, lag_max)
rho_ar1 <- empirical_autocor(X_ar1, lag_max)
# Compare with acf
acf_ar1 <- acf(X_ar1, lag.max=lag_max, main="ACF AR(1)", plot=TRUE)
all.equal(as.numeric(acf_ar1$acf), rho_ar1)
# Theoretical ACF for AR(1)
rho_theo_ar1 <- phi^(0:lag_max)
# Plot: empirical vs theoretical ACF
plot(0:lag_max, rho_ar1, type="b", pch=16, col="red",
ylim=c(-0.5,1), xlab="Lag", ylab="Autocorrelation",
main="AR(1): Empirical vs Theoretical ACF")
lines(0:lag_max, rho_theo_ar1, type="b", lty=2, pch=1, col="blue")
legend("topright", legend=c("Empirical","Theoretical"), col=c("red","blue"),
pch=c(16,1), lty=c(1,2), bty="n")
# Empirical distance correlation
dcor_ar1 <- dcor_manual(X_ar1, lag_max)
# Theoretical distance correlation: for Gaussian AR(1), compute for each lag
dcor_theo_ar1 <- sapply(0:lag_max, function(h) {
if(h==0) return(1)
theoretical_dcor(phi^h)
})
# Plot: empirical vs theoretical distance correlation
plot(0:lag_max, dcor_ar1, type="b", pch=16, col="red",
ylim=c(0,1), xlab="Lag", ylab="Distance Correlation",
main="AR(1): Empirical vs Theoretical Distance Correlation")
lines(0:lag_max, dcor_theo_ar1, type="b", lty=2, pch=1, col="blue")
legend("topright", legend=c("Empirical","Theoretical"), col=c("red","blue"),
pch=c(16,1), lty=c(1,2), bty="n")
n <- 500
theta <- 0.5
sigma_ma1 <- 2
# Innovations
eps_ma1 <- rnorm(n, 0, sigma_ma1)
X_ma1 <- numeric(n)
# First observation with stationary variance
X_ma1[1] <- rnorm(1, mean = 0, sd = sigma_ma1 * sqrt(1 + theta^2))
# Generate rest of the process
for(t in 2:n) X_ma1[t] <- eps_ma1[t] + theta * eps_ma1[t-1]
# Plot time series
plot(X_ma1, type="l", main="MA(1) Process", ylab="X_t")
# Empirical ACF
lag_max <- 20
rho_ma1 <- empirical_autocor(X_ma1, lag_max)
# Compare with acf()
acf_ma1 <- acf(X_ma1, lag.max=lag_max, main="ACF MA(1)", plot=TRUE)
all.equal(as.numeric(acf_ma1$acf), rho_ma1)
# Theoretical ACF
gamma0_ma1 <- sigma_ma1^2 * (1 + theta^2)
gamma1_ma1 <- sigma_ma1^2 * theta
rho_theo_ma1 <- c(1, gamma1_ma1 / gamma0_ma1, rep(0, lag_max-1))
# Plot: empirical vs theoretical ACF
plot(0:lag_max, rho_ma1, type="b", pch=16, col="red",
ylim=c(-0.5,1), xlab="Lag", ylab="Autocorrelation",
main="MA(1): Empirical vs Theoretical ACF")
lines(0:lag_max, rho_theo_ma1, type="b", lty=2, pch=1, col="blue")
legend("topright", legend=c("Empirical","Theoretical"), col=c("red","blue"),
pch=c(16,1), lty=c(1,2), bty="n")
# Empirical distance correlation
dcor_ma1 <- dcor_manual(X_ma1, lag_max)
# Theoretical distance correlation
dcor_theo_ma1 <- sapply(0:lag_max, function(h) {
if(h==0) return(1)
if(h==1) return(theoretical_dcor(gamma1_ma1 / gamma0_ma1))
return(0)
})
# Plot: empirical vs theoretical distance correlation
plot(0:lag_max, dcor_ma1, type="b", pch=16, col="red",
ylim=c(0,1), xlab="Lag", ylab="Distance Correlation",
main="MA(1): Empirical vs Theoretical Distance Correlation")
lines(0:lag_max, dcor_theo_ma1, type="b", lty=2, pch=1, col="blue")
legend("topright", legend=c("Empirical","Theoretical"), col=c("red","blue"),
pch=c(16,1), lty=c(1,2), bty="n")
rm(list=ls())
# Install and load required packages
# install.packages("dCovTS")
library(dCovTS)
# Theoretical distance correlation formula from Székely et al.
# MEASURING AND TESTING DEPENDENCE BY CORRELATION OF DISTANCES
theoretical_dcor <- function(rho) {
# rho = 0
numerator <- rho * asin(rho) + sqrt(1 - rho^2) - rho * asin(rho / 2) - sqrt(4 - rho^2) + 1
denominator <- 1 + pi/3 - sqrt(3)
return(sqrt(numerator / denominator))
}
# empirical autocovariance
empirical_autocov <- function(x, lag.max = 20) {
n <- length(x)
x_bar <- mean(x)
sapply(0:lag.max, function(h) {
sum((x[1:(n-h)] - x_bar)*(x[(1+h):n] - x_bar)) / n
})
}
# Function to compute empirical autocorrelation manually
empirical_autocor <- function(x, lag.max = 20) {
acov <- empirical_autocov(x, lag.max)
acov / acov[1]
}
# Theoretical distance correlation for standard normals (Székely et al. 2007)
theoretical_dcor_normal <- function(rho) {
# rho = correlation
(rho * asin(rho) + sqrt(1 - rho^2) -  rho * asin(rho/2) - sqrt(4 - rho^2) + 1) /
(1 + pi/3 - sqrt(3))
}
n <- 500
sigma_wn <- 5
X_wn <- rnorm(n, mean = 0, sd = sigma_wn)
# Plot the time series
plot(X_wn, type = "l", main = "White Noise", ylab = "X_t")
# Compute manual autocovariance and autocorrelation
lag_max <- 20
gamma_wn <- empirical_autocov(X_wn, lag_max)
rho_wn <- empirical_autocor(X_wn, lag_max)
# Compare with acf()
acf_wn = acf(X_wn, lag.max = lag_max, main = "ACF White Noise", plot = TRUE)
all.equal(as.numeric(acf_wn$acf), rho_wn)
# Theoretical ACF for white noise
rho_theo_wn <- c(1, rep(0, lag_max))
# Plot: empirical vs theoretical ACF
plot(0:lag_max, rho_wn, type="b", pch=16, col="red",
ylim=c(-0.5,1), xlab="Lag", ylab="Autocorrelation",
main="White Noise: Empirical vs Theoretical ACF")
lines(0:lag_max, rho_theo_wn, type="b", lty=2, pch=1, col="blue")
legend("topright", legend=c("Empirical", "Theoretical"), col=c("red","blue"),
pch=c(16,1), lty=c(1,2), bty="n")
#----------------------------
# Distance correlation
#----------------------------
library(energy)
dcor_manual <- function(x, lag.max = 20) {
n <- length(x)
sapply(0:lag.max, function(h) {
if(h == 0) return(1)
energy::dcor(x[1:(n-h)], x[(1+h):n])
})
}
dcor_wn <- dcor_manual(X_wn, lag_max)
# compare with ADCF from dCovTS
dcor_wn_2 = ADCF(X_wn, MaxLag = lag_max)
all.equal(dcor_wn, as.vector(dcor_wn_2))
# Theoretical distance correlation: WN is i.i.d. => rho=0 for lag>0
dcor_theo <- sapply(0:lag_max, function(h) if(h==0) 1 else theoretical_dcor_normal(0))
# Plot: empirical vs theoretical distance correlation
plot(0:lag_max, dcor_wn, type="b", pch=16, col="red",
ylim=c(0,1), xlab="Lag", ylab="Distance Correlation",
main="White Noise: Empirical vs Theoretical Distance Correlation")
lines(0:lag_max, dcor_theo, type="b", lty=2, pch=1, col="blue")
legend("topright", legend=c("Empirical", "Theoretical"), col=c("red","blue"),
pch=c(16,1), lty=c(1,2), bty="n")
setwd("~/GitHub/Forecasting")
knitr::opts_chunk$set(echo = TRUE)
library(doSNOW)
library(fpp3)
library(forecast)
library(patchwork)
library(dCovTS)
library(scoringRules)
set.seed(2)
google_2018 <- gafa_stock |>
filter(Symbol == "GOOG", year(Date) == c(2018) )
google_2018 |>
autoplot(Close) +
labs(y = "Closing stock price ($USD)")
google_2018 |>
ACF(Close) |>
autoplot()
google_2018 |>
autoplot(difference(Close)) +
labs(y = "Change in Google closing stock price ($USD)")
n<-length(google_2018$Close)
H<-20  ## How many steps ahead?
traindata<-google_2018$Close[1:(n-H)]
testdata<-google_2018$Close[(n-(H-1)):n]
ntrain<-length(traindata)
google_2018 |>
autoplot(difference(Close)) +
labs(y = "Change in Google closing stock price ($USD)")
n<-length(google_2018$Close)
H<-20  ## How many steps ahead?
traindata<-google_2018$Close[1:(n-H)]
testdata<-google_2018$Close[(n-(H-1)):n]
ntrain<-length(traindata)
library(forecast)
# Fit AR(1) - treats it as a simple numeric vector
ar1_model <- Arima(traindata, order = c(1, 0, 0))
# Forecast
predictions <- forecast(ar1_model, h = H)
test_ts <- ts(testdata, start = ntrain + 1, end = ntrain + length(testdata))
# Plot
autoplot(predictions) +
autolayer(test_ts, color = "red", size = 1) +
labs(title = "AR(1) Forecast", y = "Close Price")
##Continue here, add Winkler score!!!
traindata |> Arima(traindata, order = c(1, 0, 0)) |> accuracy(google_stock, list(winkler = winkler_score), level = 80)
library(forecast)
# Fit AR(1) - treats it as a simple numeric vector
ar1_model <- Arima(traindata, order = c(1, 0, 0))
# Forecast
predictions <- forecast(ar1_model, h = H)
test_ts <- ts(testdata, start = ntrain + 1, end = ntrain + length(testdata))
# Plot
autoplot(predictions) +
autolayer(test_ts, color = "red", size = 1) +
labs(title = "AR(1) Forecast", y = "Close Price")
traindata |> Arima(traindata, order = c(1, 0, 0)) |> accuracy(google_stock, list(winkler = winkler_score), level = 80)
## CRPS/Energy distance values
ARsim <- replicate(100, {
simulate(predictions$model, nsim = H, future = TRUE, bootstrap = FALSE)
})
crps_values <- numeric(H)
for(i in 1:H) {
crps_values[i] <- crps_sample(y = testdata[i],
dat = ARsim[i, ])
}
# Mean CRPS across all forecast horizons
mean_crps_AR <- mean(crps_values)
